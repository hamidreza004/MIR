{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    <h2>\n",
    "       فاز سوم پروژه بازیابی اطلاعات - خوشه‌بندی\n",
    "    </h2>\n",
    "</div>\n",
    "<p></p>\n",
    "<div dir=\"rtl\">\n",
    "اعضای گروه: حمیدرضا هدایتی، حامد علی‌محمدزاده، آرمین سعادت‌بروجنی\n",
    "<p></p><p></p><p></p><p></p>\n",
    "</div>\n",
    "<p></p><p></p><p></p><p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<p></p><p></p><p></p><p></p>\n",
    "    اجرای این نوتبوک ۲۰ دقیقه زمان می‌برد که ۱۵ دقیقه آن مربوط به تعیین مقدار مناسب hyper_parameter ها است که عملا ۱ بار انجام شود کافی است.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    <h3>\n",
    "       نصب نیازمندی‌های پروژه:\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../../\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /home/rmool/.local/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (1.5.2)\n",
      "Requirement already satisfied: matplotlib in /home/rmool/.local/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: numpy in /home/rmool/.local/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (1.17.3)\n",
      "Requirement already satisfied: hazm==0.7.0 in /home/rmool/miniconda3/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: pandas==1.1.3 in /home/rmool/miniconda3/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (1.1.3)\n",
      "Requirement already satisfied: nltk==3.3 in /home/rmool/miniconda3/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (3.3)\n",
      "Requirement already satisfied: tk==0.1.0 in /home/rmool/miniconda3/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (0.1.0)\n",
      "Requirement already satisfied: scikit-learn==0.23.2 in /home/rmool/miniconda3/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (0.23.2)\n",
      "Requirement already satisfied: gensim==3.8.3 in /home/rmool/miniconda3/lib/python3.7/site-packages (from -r requirements.txt (line 9)) (3.8.3)\n",
      "Requirement already satisfied: selenium==3.141.0 in /home/rmool/miniconda3/lib/python3.7/site-packages (from -r requirements.txt (line 10)) (3.141.0)\n",
      "Requirement already satisfied: networkx==2.5 in /home/rmool/miniconda3/lib/python3.7/site-packages (from -r requirements.txt (line 11)) (2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/rmool/miniconda3/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 2)) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/rmool/.local/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 2)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/rmool/.local/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/rmool/.local/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 2)) (7.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/rmool/.local/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 2)) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/rmool/.local/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 2)) (2020.6.20)\n",
      "Requirement already satisfied: libwapiti>=0.2.1; platform_system != \"Windows\" in /home/rmool/miniconda3/lib/python3.7/site-packages (from hazm==0.7.0->-r requirements.txt (line 4)) (0.2.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/rmool/miniconda3/lib/python3.7/site-packages (from pandas==1.1.3->-r requirements.txt (line 5)) (2020.1)\n",
      "Requirement already satisfied: six in /home/rmool/miniconda3/lib/python3.7/site-packages (from nltk==3.3->-r requirements.txt (line 6)) (1.12.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/rmool/miniconda3/lib/python3.7/site-packages (from scikit-learn==0.23.2->-r requirements.txt (line 8)) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/rmool/miniconda3/lib/python3.7/site-packages (from scikit-learn==0.23.2->-r requirements.txt (line 8)) (0.17.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/rmool/miniconda3/lib/python3.7/site-packages (from gensim==3.8.3->-r requirements.txt (line 9)) (4.1.2)\n",
      "Requirement already satisfied: urllib3 in /home/rmool/miniconda3/lib/python3.7/site-packages (from selenium==3.141.0->-r requirements.txt (line 10)) (1.24.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/rmool/miniconda3/lib/python3.7/site-packages (from networkx==2.5->-r requirements.txt (line 11)) (4.4.1)\n",
      "Requirement already satisfied: yellowbrick in /home/rmool/miniconda3/lib/python3.7/site-packages (1.2.1)\n",
      "Requirement already satisfied: scikit-learn<0.24,>=0.20 in /home/rmool/miniconda3/lib/python3.7/site-packages (from yellowbrick) (0.23.2)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /home/rmool/.local/lib/python3.7/site-packages (from yellowbrick) (0.10.0)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.2 in /home/rmool/.local/lib/python3.7/site-packages (from yellowbrick) (3.3.2)\n",
      "Requirement already satisfied: scipy<1.6,>=1.0.0 in /home/rmool/.local/lib/python3.7/site-packages (from yellowbrick) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.13.0 in /home/rmool/.local/lib/python3.7/site-packages (from yellowbrick) (1.17.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/rmool/miniconda3/lib/python3.7/site-packages (from scikit-learn<0.24,>=0.20->yellowbrick) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/rmool/miniconda3/lib/python3.7/site-packages (from scikit-learn<0.24,>=0.20->yellowbrick) (2.1.0)\n",
      "Requirement already satisfied: six in /home/rmool/miniconda3/lib/python3.7/site-packages (from cycler>=0.10.0->yellowbrick) (1.12.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/rmool/.local/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/rmool/.local/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/rmool/miniconda3/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/rmool/.local/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.2.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/rmool/.local/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (7.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install yellowbrick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    <h3>\n",
    "        ایمپورت کردن پکیج‌های مورد نیاز:\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/rmool/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/rmool/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from main import JSON_to_clustering_arrays \n",
    "from yellowbrick.cluster import intercluster_distance, kelbow_visualizer\n",
    "from clusterings import k_means, gmm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from clusterings import hierarchical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    <h3>\n",
    "       تحلیل اطلاعات فایل جیسون و ایجاد w2v و tf_idf:\n",
    "    </h3>\n",
    "<p></p>    \n",
    "لینک‌ها خوانده و ذخیره می‌شود. تگ‌های اصلی با شماره ۰ تا ۱۳ ذخیره می‌شود.\n",
    "<p></p>\n",
    "summery و title با هم ترکیب شده و به فضایTF_IDF و Word2Vec برده می‌شود.\n",
    "<p></p>\n",
    "    برای TF_IDF در گام اول بعد فضا برابر تعداد term ها در نظر گرفته می‌شود. در گام بعد با استفاده از PCA کاهش ابعاد صورت می‌گیرد چرا که فاصله در ابعاد بالا مبنای خوبی برای الگوریتم k_means نیست.\n",
    "<p></p>\n",
    "    تبدیل Word2Vec توسط کتابخانه موجود با پارامترهای پیش‌فرض انجام می‌شود. تنها پارامتری که باید تعیین شود ابعاد فضا است که عددی زیر ۱۰۰ در نظر گفته می‌شود.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf, w2v, tags, links, df = JSON_to_clustering_arrays(\"./data/phase3/hamshahri.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dim = 50\n",
    "random_state = 12\n",
    "tf_idf = PCA(features_dim, random_state=random_state).fit_transform(tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    <h2>\n",
    "        بررسی پارامترهای k_means:\n",
    "    </h2>\n",
    "    <p></p>\n",
    "    KMeans(n_clusters=n_clusters, random_state=random_state, n_init=10, max_iter=300)\n",
    "    <p></p>\n",
    "    random_state یک عدد دلخواه تعیین می‌شود تا با ثابت ماندن بقیه پارامترها جواب یکسان گرفته شود.\n",
    "    <p></p>\n",
    "    در گام اول تعداد خوشه‌ها (n_clusters) تعیین می‌شود.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    <h4>\n",
    "        محاسبه تعداد خوشه‌ها بدون استفاده از tags:\n",
    "    </h4>\n",
    "    <p></p>\n",
    "    نمودار تابع هزینه (مجموع مجذور فاصله هر نقطه از مرکز) بر حسب تعداد خوشه‌ها رسم می‌شود.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia_tfidf = []\n",
    "for i in range(2, 20):\n",
    "    inertia_tfidf.append(k_means.get_cost(tf_idf, random_state=random_state, n_clusters=i))\n",
    "print('TF-IDF:')\n",
    "ax = sns.lineplot(x=range(2, 20), y=inertia_tfidf);\n",
    "ax.set(xlabel='n_clusters', ylabel='inertia')\n",
    "plt.show()\n",
    "\n",
    "inertia_w2v = []\n",
    "for i in range(2, 20):\n",
    "    inertia_w2v.append(k_means.get_cost(w2v, random_state=random_state, n_clusters=i))\n",
    "print('W2v:')\n",
    "ax = sns.lineplot(x=range(2, 20), y=inertia_w2v);\n",
    "ax.set(xlabel='n_clusters', ylabel='inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    همانطور که انتظار میرفت با افزایش تعداد خوشه‌ها، هزینه کمتر شد. اما به دنبال نقطه‌ای هستیم که کاهش معناداری داشته باشد که از نمودارهای بالا به دست نیامد.\n",
    "<p></p>\n",
    "    برای دقت بیشتر و در نظر گرفتن زمان مورد نیاز برای رسیدن به جواب، میتوان از  Elbow method استفاده کرد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TF_IDF:')\n",
    "_ = kelbow_visualizer(KMeans(random_state=random_state), tf_idf, k=(2,16), metric='silhouette');\n",
    "print('Word2Vec:')\n",
    "_ = kelbow_visualizer(KMeans(random_state=random_state), w2v, k=(2,16), metric='silhouette');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    بنابراین تعداد خوشه‌ها در هر دو روش ۵ به دست آمد.\n",
    "<p></p>\n",
    "    با مقدار پیش‌فرض پارامترهای KMeans خوشه‌بندی را انجام داده و نتایج ارزیابی را نمایش می‌دهیم. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means.get_evaluation_dataframe(tf_idf, w2v, tags, 5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    برای افزایش کیفیت خوشه‌بندی، میتوان تعداد ابعاد را کمی بیشتر کرد.\n",
    "    <p></p>\n",
    "    در مورد w2v، با افزایش بعد مقدار epoches نیز از ۱۰ به ۳۲ افزایش یافت تا ویژگی‌های جدید بهتر آموخته شوند.\n",
    "    <p></p>\n",
    "    مشابه این فرایند برای tf_idf نیز اعمال شد. فضا از ۵۰ به ۴۰۰ تغییر یافت و برای رسیدن به نتیجه مطلوب تعداد حالات بیشتری (با randomness بیشتر ) بررسی شد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_tfidf, enhanced_w2v, tags, links, df = JSON_to_clustering_arrays(\"./data/phase3/hamshahri.json\", tf_idf_features=1000, w2v_min_count=2, w2v_epochs=32, w2v_vector_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dim = 400\n",
    "enhanced_tfidf = PCA(features_dim, random_state=random_state).fit_transform(enhanced_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, best_random_tfidf, best_random_w2v = k_means.get_advanced_results(enhanced_tfidf, enhanced_w2v, tags, 5, 5)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    همانطور که مشاهده می‌شود نتایج به شکل معناداری بهبود یافت. دلیل اصلی این بهبود افزایش بعد نیست بلکه اجرای الگوریتم با نقاط شروع متفاوت و با random_state های متفاوت است که باعث می‌شود نقاط بهینه محلی بیشتری را بررسی کرده و بهترین آن‌ها را به عنوان بهینه اصلی انتخاب کند.\n",
    "    <p></p><p></p>\n",
    "    در زیر خوشه‌ها بر اساس رنگ مشخص شده‌اند. این نمایش بر حسب ۲ ویژگی بارز شناسایی شده توسط PCA است.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means.PCA2_plot(enhanced_tfidf, 5, best_random_tfidf, tags, \"PCA Reduction of TF_IDF\")\n",
    "k_means.PCA2_plot(enhanced_w2v, 5, best_random_w2v, tags, \"PCA Reduction of Word2Vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    موقعیت خوشه‌ها نسبت به هم با معیار فاصله بین خوشه‌ای به شکل زیر است:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TF_IDF:')\n",
    "_ = intercluster_distance(KMeans(n_clusters=5, random_state=best_random_tfidf), enhanced_tfidf)\n",
    "print('Word2Vec:')\n",
    "_ = intercluster_distance(KMeans(n_clusters=5, random_state=best_random_w2v), enhanced_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    <h4>\n",
    "        محاسبه تعداد خوشه‌ها با استفاده از tags:\n",
    "    </h4>\n",
    "    <p></p>\n",
    "    دسته‌های اصلی به عنوان ground truth استفاده می‌شوند. تعداد این دسته‌ها ۱۴ تاست پس تعداد خوشه‌ها برابر ۱۴ هم امتحان می‌کنیم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means.get_evaluation_dataframe(tf_idf, w2v, tags, 14, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    <h4>\n",
    "        نتایج برگزیده k_means:\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_results, best_random_tfidf, best_random_w2v = k_means.get_advanced_results(tf_idf, enhanced_w2v, tags, 14, 14)\n",
    "kmeans_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    مشاهده می‌شود که عملکرد خوشه‌بندی با ۱۴ خوشه بهبود می‌یابد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means.PCA2_plot(tf_idf, 14, best_random_tfidf, tags, \"PCA Reduction of TF_IDF\")\n",
    "k_means.PCA2_plot(enhanced_w2v, 14, best_random_w2v, tags, \"PCA Reduction of Word2Vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TF_IDF:')\n",
    "_ = intercluster_distance(KMeans(n_clusters=14, random_state=best_random_tfidf), tf_idf)\n",
    "print('Word2Vec:')\n",
    "_ = intercluster_distance(KMeans(n_clusters=14, random_state=best_random_w2v), enhanced_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    همانطور که از نمودار بالا برداشت می‌شود، روش w2v خیلی بهتر خوشه‌ها را از هم تفکیک کرده است.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    <h4>\n",
    "        بررسی سایر پارامترها: n_init و max_iter\n",
    "    </h4>\n",
    "    <p></p>\n",
    "    تا اینجا این مقادیر به صورت پیش‌فرض به ترتیب ۱۰ و ۳۰۰ بوده‌اند.\n",
    "    <p></p>\n",
    "    n_init تعداد بارهایی است که به ازای هر بار صدا زدن تابع KMeans الگوریتم انجام شده و بهترین جواب بازگردانده می‌شود.\n",
    "    <p></p>\n",
    "    max_iter حداکثر تعداد مراحلی است که در هر بار اجرای الگوریتم طی می‌شود.\n",
    "    <p></p>\n",
    "    <h5>\n",
    "        بررسی n_init:\n",
    "    </h5>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means.evaluate_n_init(tf_idf, enhanced_w2v, tags, 14, 14, best_random_tfidf, best_random_w2v, [1, 5, 10, 20, 30])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    از آنجا که در کد با چندین random_state حالات مختلف بررسی شده و بهترین آن‌ها انتخاب می‌شود، به نوعی همان کار n_init دارد دستی انجام می‌شود و دیگر تاثیر چندانی ندارد. به جز در یک مورد که برای w2v با n_init=1 مقدار غیر بهینه به دست آمده است که آن هم با تکرار مجدد برطرف می‌شود.\n",
    "    نتیجه اینکه n_init بیشتر از حدودا ۵ صرفا بار محاسبات را افزایش می‌دهد و تاثیر مثبتی ندارد.\n",
    "    <p></p>\n",
    "    <h5>\n",
    "        بررسی max_iter:\n",
    "    </h5>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means.evaluate_max_iter(tf_idf, enhanced_w2v, tags, 14, 14, best_random_tfidf, best_random_w2v, [10, 50, 100, 300, 500])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    برای مقادیر ۱۰ و ۵۰ که کمتر از حالت پیش‌فرض هستند مقادیر غیر بهینه به دست آمد. اما برای مقادیر بیشتر از ۱۰۰ الگوریتم قبل از رسیدن به max_iter همگرا شده است. در کل چون در این مسئله خیلی زود همگرایی اتفاق رخ می‌دهد max_iter چندان تاثیری ندارد.\n",
    "    <p></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    <h2>\n",
    "        بررسی پارامترهای gmm:\n",
    "    </h2>\n",
    "    <p></p>\n",
    "    GMM دارای ۲ هایپرپارامتر مهم است: n_components, covariance_type\n",
    "    <p></p>\n",
    "    در k_means تعداد خوشه‌ها به صورت تجربی ۵ به دست آمد. از طرفی میدانیم ۱۴ دسته اصلی داریم. پس مقدار n_compenents را بین مقادیر ۵ تا ۱۵ بررسی میکنیم.\n",
    "    <p></p>\n",
    "    covariance_type چهار حالت دارد که هر ۴ مورد را بررسی میکنیم: full, tied, diag, spherical\n",
    "    <p></p>\n",
    "    این فرآیند برای هر دو حالت enhanced_tfidf و tf_idf انجام می‌شود تا تاثیر بعد فضا هم بررسی شود.\n",
    "    <p></p>\n",
    "    این کارها به ازای tf_idf و w2v انجام می‌شود.\n",
    "    <p></p>\n",
    "    بنابراین ۲ * ۲ * ۴ * ۱۱ یعنی ۱۷۶ حالت باید بررسی شود.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMI_results = gmm.get_result_df(tf_idf, w2v, tags)\n",
    "AMI_results_higher_dim = gmm.get_result_df(enhanced_tfidf, enhanced_w2v, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMI_results.query('vector == \"tf_idf\" and metric == \"AMI\"').sort_values(by=['score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMI_results.query('vector == \"w2v\" and metric == \"AMI\"').sort_values(by=['score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMI_results_higher_dim.query('vector == \"tf_idf\" and metric == \"AMI\"').sort_values(by=['score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMI_results_higher_dim.query('vector == \"w2v\" and metric == \"AMI\"').sort_values(by=['score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    بنابراین برای w2v حالت با فضای بعد بالاتر مناسب است اما برای tf_idf فضای با بعد کمتر بهتر عمل کرد.\n",
    "    بنابراین w2v با بعد ۱۲۸ و tf_idf با بعد ۵۰ محاسبه خواهد شد.\n",
    "    <p></p>\n",
    "    <p></p>\n",
    "    برای tf_idf با قطعیت حالت full بهتر عمل می‌کند. تعداد خوشه‌ها بین ۹ تا ۱۴ مناسب است و آنچنان فرقی ندارد. چون می‌دانیم ۱۴ دسته اصلی داریم همان ۱۴ را برای تعداد خوشه‌های tf_idf در نظر میگیریم.\n",
    "    <p></p>\n",
    "    برای حالت w2v هم diag مناسب به نظر می‌رسد هم full اما diag تصمیم محکم‌تر و به صرفه‌تری است چرا که تعداد پارامتر‌های کمتری دارد. تعداد خوشه‌ها بین ۱۰ تا ۱۳ معقول است. چون میدانیم تعداد دسته‌های اصلی ۱۴ تاست برای w2v تعداد خوشه ۱۳ را انتخاب می‌کنیم که نزدیک‌تر به ۱۴ باشد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AMI_res = pd.concat([AMI_results.query('vector == \"tf_idf\"'),AMI_results_higher_dim.query('vector == \"w2v\"')], axis=0, ignore_index=False)\n",
    "sns.relplot(data=AMI_res, x='n_components', y='score', row='vector', col='covariance_type', hue=\"metric\", kind='line');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    <h4>\n",
    "        بررسی max_iter برای tf_idf:\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = [50, 100, 200]\n",
    "for max_iter in max_iters:\n",
    "    print(\"max_iter: \" + str(max_iter) + \" --> AMI: \" + str(gmm.get_AMI(tf_idf, tags, 14, 'full', max_iter)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    <h4>\n",
    "        بررسی max_iter برای w2v:\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = [50, 100, 200]\n",
    "for max_iter in max_iters:\n",
    "    print(\"max_iter: \" + str(max_iter) + \" --> AMI: \" + str(gmm.get_AMI(enhanced_w2v, tags, 14, 'full', max_iter)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "        بنابراین max_iter تاثیر خاصی ندارد چون خیلی زود همگرا می‌شود و همان مقدار ۱۰۰ برایش مناسب است.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    <h4>\n",
    "        نتایج برگزیده gmm:\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_param = {'n_components': 14, 'covariance_type': 'full', 'max_iter': 100}\n",
    "w2v_param = {'n_components': 13, 'covariance_type': 'diag', 'max_iter': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_results = gmm.get_evaluation_dataframe(tf_idf, tfidf_param, enhanced_w2v, w2v_param, tags)\n",
    "gmm_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    <h2>\n",
    "        بررسی پارامترهای hierarchical:\n",
    "    </h2>\n",
    "    <p></p>\n",
    "    از روش AgglomerativeClustering استفاده میکنیم.\n",
    "    <p></p>\n",
    "    دارای ۳ هایپرپارامتر مهم است: n_clusters, linkage, affinity\n",
    "    <p></p>\n",
    "    در k_means تعداد خوشه‌ها به صورت تجربی ۵ به دست آمد. از طرفی میدانیم ۱۴ دسته اصلی داریم. پس مقدار n_clusters را بین مقادیر ۵ تا ۱۵ بررسی میکنیم.\n",
    "    <p></p>\n",
    "    linkage چهار حالت دارد که هر ۴ مورد را بررسی میکنیم: ward, complete, average, single\n",
    "    <p></p>\n",
    "    affinity پنج حالت دارد: euclidean, l1, l2, manhattan.\n",
    "    <p></p>\n",
    "    این کارها به ازای tf_idf و w2v انجام می‌شود.\n",
    "    <p></p>\n",
    "    بنابراین ۲ * ۴ * ۴ * ۱۱ یعنی ۳۵۲ حالت باید بررسی شود.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMI_results_hier = hierarchical.get_result_df(tf_idf, enhanced_w2v, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMI_results_hier.query('vector == \"tf_idf\" and metric == \"AMI\"').sort_values(by=['score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMI_results_hier.query('vector == \"w2v\" and metric == \"AMI\"').sort_values(by=['score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    <p></p>\n",
    "    بنابراین می‌توان با قاطعیت گفت که linkaga=ward بهترین گزینه است برای tf_idf و w2v.\n",
    "    <p></p>\n",
    "    از طرفی ward تنها با euclidean سازگاری دارد. پس عملا همان حالت پیش‌فرض تابع نتیجه شد.\n",
    "    <p></p>\n",
    "    n_clusters برای tf_idf بین ۱۴ و ۱۵ نتیجه خوب داده‌است بنابراین تعداد خوشه‌ها را ۱۴ در نظر میگیرم.\n",
    "    <p></p>\n",
    "    برای w2v تعداد خوشه‌ها بین ۹ تا ۱۴ جواب معقول و بهینه‌ای داده‌است اما ۱۱ و ۱۳ بهینه‌تر از بقیه هستند. با توجه به اینکه تعداد دسته‌های اصلی ۱۴ تاست، بین ۱۱ و ۱۳ مقدار ۱۳ را به عنوان تعداد خوشه انتخاب می‌کنیم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=AMI_results_hier, x='n_clusters', y='score', row='vector', col='linkage', hue=\"metric\", kind='line');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical.show_dendrogram(tf_idf, 'ward', 'euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    در نمودار بالا تعداد دسته‌ها ۱۶ تا است که این عدد نزدیک به تعداد خوشه‌های tf_idf یعنی ۱۴ است. اگر دقت شود دو دسته دارای تنها ۲ عضو هستند که با حذف آن‌ها به همان ۱۴ دسته میرسیم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical.show_dendrogram(enhanced_w2v, 'ward', 'euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    در نمودار بالا تعداد دسته‌ها ۱۶ تاست که با مرج کردن دسته‌های زیر ۱۰۰ عضو به ۱۳ دسته میرسیم که همان تعداد خوشه‌های w2v است.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    <h4>\n",
    "        نتایج برگزیده hierarchical:\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_param = {'n_clusters': 14, 'linkage': 'ward', 'affinity': 'euclidean'}\n",
    "w2v_param = {'n_clusters': 13, 'linkage': 'ward', 'affinity': 'euclidean'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_results = hierarchical.get_evaluation_dataframe(tf_idf, tfidf_param, enhanced_w2v, w2v_param, tags)\n",
    "hierarchical_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    <h2>\n",
    "        نتایج نهایی خوشه‌بند‌ها:\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    <h4>\n",
    "        پارامترهای برگزیده kmeans:\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_tfidf_param = {'n_clusters': 14, 'n_init': 10, 'max_iter': 300, 'random_state': best_random_tfidf}\n",
    "kmeans_w2v_param = {'n_clusters': 14, 'n_init': 10, 'max_iter': 300, 'random_state': best_random_w2v}\n",
    "kmeans_df = k_means.final(tf_idf, kmeans_tfidf_param, enhanced_w2v, kmeans_w2v_param, tags, links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    <h4>\n",
    "        پارامترهای برگزیده gmm:\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_tfidf_param = {'n_components': 14, 'covariance_type': 'full', 'max_iter': 100}\n",
    "gmm_w2v_param = {'n_components': 13, 'covariance_type': 'diag', 'max_iter': 100}\n",
    "gmm_df = gmm.final(tf_idf, gmm_tfidf_param, enhanced_w2v, gmm_w2v_param, tags, links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    <h4>\n",
    "        پارامترهای برگزیده hierarchical:\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_tfidf_param = {'n_clusters': 14, 'linkage': 'ward', 'affinity': 'euclidean'}\n",
    "hierarchical_w2v_param = {'n_clusters': 13, 'linkage': 'ward', 'affinity': 'euclidean'}\n",
    "hierarchical_df = hierarchical.final(tf_idf, hierarchical_tfidf_param, enhanced_w2v, hierarchical_w2v_param, tags, links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    <h4>\n",
    "        نتایج نهایی:\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([kmeans_df, gmm_df, hierarchical_df], axis=0, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
